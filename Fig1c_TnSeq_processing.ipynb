{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "######################################################\n",
    "import csv\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = ''\n",
    "fastq_path = 'fastq_Tn/'\n",
    "\n",
    "files = ['ks193','ks195']\n",
    "\n",
    "skewer_option = '-Q 10'\n",
    "skewer_adapter = 'AGATCGGAAGAGCACACGTC'\n",
    "\n",
    "cutadapt_ME_motif = 'GGTTGAGATGTGTATAAGAGACAG'\n",
    "\n",
    "inpath = fastq_path\n",
    "outpath = filepath\n",
    "bowtie_input_extension = '-trimmed-ctadpt.fastq'\n",
    "\n",
    "mapping = '_5map'\n",
    "gene_type = '_gene'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ks193\n",
      "ks195\n"
     ]
    }
   ],
   "source": [
    "skewer = '/home/kazuki/^data_analysis/analtools/skewer022/skewer-0.2.2-linux-x86_64'\n",
    "\n",
    "log_file = filepath+'log_Tn_skewer.txt'\n",
    "logs = open(log_file, 'w')\n",
    "logs.close()\n",
    "\n",
    "for f in files:\n",
    "    file_path = fastq_path+f+'.fastq'\n",
    "    \n",
    "    command = '%s %s -x %s %s >> %s' % (\n",
    "        skewer,\n",
    "        skewer_option,\n",
    "        skewer_adapter,\n",
    "        file_path,\n",
    "        log_file\n",
    "        ) \n",
    "    \n",
    "    logs = open(log_file, 'a+')\n",
    "    logs.write('\\n\\n'+f+'\\n')\n",
    "    logs.close()\n",
    "    \n",
    "    os.system(command)\n",
    "\n",
    "    print f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ks193\n",
      "ks195\n"
     ]
    }
   ],
   "source": [
    "log_file = filepath+'log_Tn_cutadapt.txt'\n",
    "logs = open(log_file, 'w')\n",
    "logs.close()\n",
    "\n",
    "for f in files:\n",
    "    cutadapt_inputfile = fastq_path+f+'-trimmed.fastq'\n",
    "    cutadapt_outputfile = fastq_path+f+'-trimmed-ctadpt.fastq'\n",
    "    \n",
    "    command = 'cutadapt -g ^%s --discard-untrimmed --minimum-lengt 10 -o %s %s >> %s' % (\n",
    "        cutadapt_ME_motif,\n",
    "        cutadapt_outputfile,\n",
    "        cutadapt_inputfile,\n",
    "        log_file\n",
    "        )\n",
    "    \n",
    "    logs = open(log_file, 'a+')\n",
    "    logs.write('\\n\\n'+f+'\\n')\n",
    "    logs.close()\n",
    "    \n",
    "    os.system(command)\n",
    "    \n",
    "    print f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ks193\n",
      "ks195\n"
     ]
    }
   ],
   "source": [
    "log_file = filepath+'log_Tn_bowtie.txt'\n",
    "logs = open(log_file, 'w')\n",
    "logs.close()\n",
    "\n",
    "path_chr = outpath + 'alignments/chr/'\n",
    "path_temp = outpath + 'tmpds/'\n",
    "\n",
    "if not os.path.exists(outpath + 'alignments/'):\n",
    "    os.makedirs(outpath + 'alignments/')\n",
    "if not os.path.exists(path_chr):\n",
    "    os.makedirs(path_chr)\n",
    "if not os.path.exists(path_temp):\n",
    "    os.makedirs(path_temp)\n",
    "\n",
    "for fname in files:\n",
    "    bowtie_command = 'bowtie -v 1 -y -m 1 -a --best --strata -S -p 2 '\\\n",
    "        '--un %s%s --max %s%s --al %s%s %s %s%s %s%s 1>> %s 2>> %s'\n",
    "        \n",
    "    bowtie_chr = bowtie_command %(\n",
    "        path_chr,\n",
    "        fname+'_nomatch.fastq',\n",
    "        path_chr,\n",
    "        fname+'_multi.fastq',\n",
    "        path_chr,\n",
    "        fname+'_match.fastq',\n",
    "        'MG1655/e_coli_MG1655',\n",
    "        inpath,\n",
    "        fname + bowtie_input_extension,\n",
    "        path_chr,\n",
    "        fname + '_match.SAM',\n",
    "        log_file,\n",
    "        log_file\n",
    "        )\n",
    "\n",
    "    logs = open(log_file, 'a+')\n",
    "    logs.write('\\n\\n###################'+fname+'\\n')\n",
    "    logs.write('\\n'+bowtie_chr+'\\n')\n",
    "    logs.close()\n",
    "\n",
    "    os.system(bowtie_chr)\n",
    "    \n",
    "    print fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def five_end_mapping(samgen,GFFgen_filename):\n",
    "    from BCBio import GFF\n",
    "    from Bio import Seq\n",
    "    outputdata1={}\n",
    "    outputdata2={}\n",
    "    GFFgen=GFF.parse(GFFgen_filename)\n",
    "    for sequence in GFFgen:\n",
    "        outputdata1[sequence.id]=[0 for x in range(len(sequence))]\n",
    "        outputdata2[sequence.id]=[0 for x in range(len(sequence))]\n",
    "        for read in samgen:\n",
    "            if read[0][0] == '@':   \n",
    "                continue\n",
    "            if read[1] == '4':      \n",
    "                continue            \n",
    "            chrom = read[2]             \n",
    "            readid = read[0]            \n",
    "            startp = int(read[3]) - 1    \n",
    "            seq = Seq.Seq(read[9])      \n",
    "            length = len(seq)           \n",
    "            if (read[1] == '16'):\n",
    "                start = startp + length - 1\n",
    "                outputdata2[chrom][start] += 1\n",
    "            if (read[1] == '0'):\n",
    "                start = startp\n",
    "                outputdata1[chrom][start] += 1\n",
    "    return [outputdata1,outputdata2] \n",
    "\n",
    "\n",
    "def readcounts_to_rpm(readcounts):\n",
    "    for chrom in readcounts.keys():\n",
    "        totalread = sum(readcounts[chrom])\n",
    "        for position in range(len(readcounts[chrom])):\n",
    "            readcounts[chrom][position]/=float(totalread)\n",
    "            readcounts[chrom][position]*=1E6            \n",
    "\n",
    "def writecountsf(rpm,filepath):  \n",
    "    import struct\n",
    "    f2=open(filepath+\"keys\",\"w\")\n",
    "    for chrom in rpm.keys():\n",
    "        f=open(filepath+\"genome\",\"wb\")\n",
    "        for position in rpm[chrom]:\n",
    "            f.write(struct.pack(\"f\",position))\n",
    "        f.close()\n",
    "        f2.write(chrom+\"\\n\")\n",
    "    f2.close()\n",
    "\n",
    "def countstowig(rpm,filestring):\n",
    "    import random\n",
    "    f=open(filestring+\".wig\",\"w\")\n",
    "    filestring=filestring.partition(\"_\")[0][-3:]\n",
    "\n",
    "    random.seed(filestring)\n",
    "    c1=random.randint(0,255)\n",
    "    random.seed(filestring+\"xxx\")\n",
    "    c2=random.randint(0,255)\n",
    "    random.seed(filestring+\"000\")\n",
    "    c3=random.randint(0,255)\n",
    "\n",
    "    f.write(\"track name=tracklabel viewLimits=-5:5 color=\"+str(c1)+','+str(c2)+','+str(c3)+\"\\n\")\n",
    "    for chrom in rpm.keys():\n",
    "        if chrom[0:3]=='chr':\n",
    "            f.write(\"fixedStep  chrom=\"+chrom+\"  start=1  step=1\\n\")\n",
    "        else:\n",
    "            f.write(\"fixedStep  chrom=\\\"\"+chrom+\"\\\"  start=1  step=1\\n\")\n",
    "\n",
    "\n",
    "        for position in rpm[chrom]:\n",
    "            f.write(str(position)+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ks193\n",
      "ks195\n"
     ]
    }
   ],
   "source": [
    "out_path=filepath+'density/'\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "for f in files:\n",
    "    samgenmain_filename=filepath+'alignments/chr/'+f+'_match.SAM'\n",
    "    f_samgenmain=open(samgenmain_filename)\n",
    "    samgenmain=csv.reader(f_samgenmain,delimiter='\\t')\n",
    "\n",
    "    gff = 'MG1655/coli.gff'\n",
    "\n",
    "    three_mapped=five_end_mapping(samgenmain,gff) ############################################################\n",
    "    pickle_readcounts = out_path+f+mapping+'_readcounts.pickle'\n",
    "    with open(pickle_readcounts, 'wb') as readcounts_f:\n",
    "        pickle.dump(three_mapped,readcounts_f)\n",
    "\n",
    "    print f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ks193\n",
      "ks195\n"
     ]
    }
   ],
   "source": [
    "in_path = filepath+'density/'\n",
    "\n",
    "for f in files:\n",
    "    readcounts_file = in_path+f+mapping+'_readcounts.pickle'\n",
    "    with open(readcounts_file, 'rb') as rf:\n",
    "        readcounts_dict = pickle.load(rf)\n",
    "    plus_readcounts = readcounts_dict[0][readcounts_dict[0].keys()[0]]\n",
    "    minus_readcounts = readcounts_dict[1][readcounts_dict[1].keys()[0]]\n",
    "    totalread = sum(plus_readcounts) + sum(minus_readcounts)\n",
    "\n",
    "    ######################################################################\n",
    "    # for readcounts\n",
    "    both_readcounts_list = []\n",
    "    for p_rc, n_rc in zip(plus_readcounts,minus_readcounts):\n",
    "        both_readcounts = p_rc+n_rc\n",
    "        both_readcounts_list.append(both_readcounts)\n",
    "\n",
    "    three_mapped_readcounts = []\n",
    "    for readcounts in readcounts_dict:    \n",
    "        for chrom in readcounts.keys():\n",
    "            three_mapped_readcounts.append({chrom:both_readcounts_list})\n",
    "\n",
    "    pickle_rpm = in_path+f+mapping+'_readcounts_BOTH.pickle'\n",
    "    with open(pickle_rpm, 'wb') as rpm_f:\n",
    "        pickle.dump(three_mapped_readcounts,rpm_f)\n",
    "     \n",
    "    ######################################################################\n",
    "    # for rpm\n",
    "    both_rpm_list = []\n",
    "    for p_rc, n_rc in zip(plus_readcounts,minus_readcounts):\n",
    "        both_rpm = p_rc+n_rc\n",
    "        both_rpm/=float(totalread)\n",
    "        both_rpm*=1E6  \n",
    "        both_rpm_list.append(both_rpm)\n",
    "\n",
    "    three_mapped_rpm = []\n",
    "    for readcounts in readcounts_dict:    \n",
    "        for chrom in readcounts.keys():\n",
    "            three_mapped_rpm.append({chrom:both_rpm_list})\n",
    "\n",
    "    pickle_rpm = in_path+f+mapping+'_rpm_BOTH.pickle'\n",
    "    with open(pickle_rpm, 'wb') as rpm_f:\n",
    "        pickle.dump(three_mapped_rpm,rpm_f)\n",
    "        \n",
    "    ######################################################################\n",
    "    # for wig file\n",
    "    density_path = in_path+f+mapping\n",
    "    writecountsf(three_mapped_rpm[0],density_path+\"_BOTH_plus_\")\n",
    "    countstowig(three_mapped_rpm[0],density_path+\"_BOTH_plus\")\n",
    "    writecountsf(three_mapped_rpm[1],density_path+\"_BOTH_minus_\")\n",
    "    countstowig(three_mapped_rpm[1],density_path+\"_BOTH_minus\")\n",
    "    \n",
    "    print f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ks193\n",
      "ks195\n"
     ]
    }
   ],
   "source": [
    "in_path = filepath+'density/'\n",
    "out_path = filepath+'expression/'\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "with open('MG1655/Ecoli_Gene_TU.pickle','rb') as GT_f:\n",
    "    Gene_TU_dict = pickle.load(GT_f)\n",
    "\n",
    "for f in files:\n",
    "    expression_dict={}\n",
    "    out_pickle=out_path+f+mapping+gene_type+'_expression_BOTH.pickle'\n",
    "    out_csv=out_path+f+mapping+gene_type+'_expression_BOTH.csv'\n",
    "    readcounts_file = in_path+f+mapping+'_readcounts.pickle'\n",
    "    \n",
    "    with open(readcounts_file, 'rb') as rf:\n",
    "        readcounts_dict = pickle.load(rf)\n",
    "    plus_readcounts = readcounts_dict[0][readcounts_dict[0].keys()[0]]\n",
    "    minus_readcounts = readcounts_dict[1][readcounts_dict[1].keys()[0]]\n",
    "    total_read = sum(plus_readcounts)+sum(minus_readcounts)\n",
    "    \n",
    "    for key in Gene_TU_dict.keys():\n",
    "        if key in expression_dict.keys():\n",
    "            print key +' is overlapping!!!'\n",
    "            continue\n",
    "        start = int(Gene_TU_dict[key][2])-1\n",
    "        end = int(Gene_TU_dict[key][3])\n",
    "        length = end-start\n",
    "        if length < 0:\n",
    "            print key + 'is shorter than zero!!!'\n",
    "            continue\n",
    "        if Gene_TU_dict[key][0] == '+':\n",
    "            reads = float(sum(plus_readcounts[start:end]))\n",
    "            reads = float(sum(minus_readcounts[start:end]))\n",
    "        if Gene_TU_dict[key][0] == '-':\n",
    "            reads = float(sum(plus_readcounts[start:end]))\n",
    "            reads = float(sum(minus_readcounts[start:end]))\n",
    "        rpc = (reads/length)*3\n",
    "        rpkm = (((reads/total_read)*1000000)/length)*1000\n",
    "        expression_dict[key]=[]\n",
    "        expression_dict[key].append(reads)\n",
    "        expression_dict[key].append(rpc)\n",
    "        expression_dict[key].append(rpkm)\n",
    "    \n",
    "    with open(out_pickle, 'wb') as op:\n",
    "        pickle.dump(expression_dict,op)           \n",
    "    \n",
    "    rpkm_DataFrame = DataFrame.from_dict(expression_dict, orient='index')\n",
    "    rpkm_DataFrame.columns = ['reads','rpc','rpkm']\n",
    "    rpkm_DataFrame.to_csv(out_csv) \n",
    "    \n",
    "    print f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
